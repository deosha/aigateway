apiVersion: v1
kind: Namespace
metadata:
  name: litellm
  labels:
    app.kubernetes.io/name: litellm
    app.kubernetes.io/part-of: ai-gateway-platform
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: litellm
  namespace: litellm
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm
  namespace: litellm
  labels:
    app.kubernetes.io/name: litellm
    app.kubernetes.io/component: proxy
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: litellm
  template:
    metadata:
      labels:
        app.kubernetes.io/name: litellm
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "4000"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: litellm
      containers:
        - name: litellm
          image: ghcr.io/berriai/litellm:main-latest
          ports:
            - name: http
              containerPort: 4000
              protocol: TCP
          env:
            - name: LITELLM_MASTER_KEY
              valueFrom:
                secretKeyRef:
                  name: litellm-secrets
                  key: master-key
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: litellm-secrets
                  key: database-url
            - name: LITELLM_LOG
              value: "DEBUG"
            # OpenTelemetry configuration
            - name: OTEL_EXPORTER
              value: "otlp_http"
            - name: OTEL_ENDPOINT
              value: "http://otel-collector.observability.svc.cluster.local:4318"
            - name: OTEL_SERVICE_NAME
              value: "litellm"
            # Redis for caching (optional)
            - name: REDIS_HOST
              value: "redis.litellm.svc.cluster.local"
            - name: REDIS_PORT
              value: "6379"
            # Callbacks for cost tracking
            - name: LITELLM_CALLBACKS
              value: "otel"
          args:
            - "--config"
            - "/etc/litellm/config.yaml"
            - "--port"
            - "4000"
            - "--detailed_debug"
          volumeMounts:
            - name: config
              mountPath: /etc/litellm
              readOnly: true
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: 2000m
              memory: 4Gi
          livenessProbe:
            httpGet:
              path: /health/liveliness
              port: 4000
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /health/readiness
              port: 4000
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            allowPrivilegeEscalation: false
      volumes:
        - name: config
          configMap:
            name: litellm-config
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: litellm
                topologyKey: kubernetes.io/hostname
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: litellm
  namespace: litellm
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: litellm
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: litellm
  namespace: litellm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: litellm
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
